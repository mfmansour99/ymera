"""
YMERA Enterprise Metrics Collection System
Production-Ready Performance Monitoring & Analytics
"""

import asyncio
import json
import time
import psutil
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union, Set
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
from contextlib import asynccontextmanager
import logging
from enum import Enum
import redis.asyncio as redis
from concurrent.futures import ThreadPoolExecutor
import gc
import sys
import platform
import socket
import uuid
from statistics import mean, median, stdev

class MetricType(Enum):
    """Enumeration of metric types"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"
    TIMER = "timer"

class MetricScope(Enum):
    """Enumeration of metric scopes"""
    SYSTEM = "system"
    AGENT = "agent"
    LEARNING = "learning"
    API = "api"
    DATABASE = "database"
    REDIS = "redis"
    AI_SERVICE = "ai_service"
    ORCHESTRATION = "orchestration"

@dataclass
class MetricPoint:
    """Individual metric data point"""
    name: str
    value: Union[int, float]
    timestamp: datetime
    metric_type: MetricType
    scope: MetricScope
    tags: Dict[str, str]
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        return {
            'name': self.name,
            'value': self.value,
            'timestamp': self.timestamp.isoformat(),
            'metric_type': self.metric_type.value,
            'scope': self.scope.value,
            'tags': self.tags,
            'metadata': self.metadata or {}
        }

@dataclass
class SystemResourceMetrics:
    """System resource utilization metrics"""
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    memory_available_mb: float
    disk_usage_percent: float
    disk_used_gb: float
    disk_free_gb: float
    network_bytes_sent: int
    network_bytes_recv: int
    load_average: List[float]
    active_connections: int
    thread_count: int
    process_count: int
    file_descriptors: int
    timestamp: datetime

@dataclass
class AgentPerformanceMetrics:
    """Individual agent performance metrics"""
    agent_id: str
    agent_type: str
    status: str
    task_count_total: int
    task_count_active: int
    task_count_completed: int
    task_count_failed: int
    average_task_duration: float
    last_activity: datetime
    memory_usage_mb: float
    cpu_usage_percent: float
    error_rate: float
    success_rate: float
    throughput_per_minute: float
    queue_size: int
    learning_score: float
    adaptation_rate: float

@dataclass
class LearningEngineMetrics:
    """Learning engine performance metrics"""
    total_learning_sessions: int
    active_learning_sessions: int
    knowledge_base_size: int
    vector_embeddings_count: int
    learning_rate: float
    adaptation_score: float
    model_accuracy: float
    training_iterations: int
    last_training_time: datetime
    feedback_count: int
    positive_feedback_ratio: float
    knowledge_retention_score: float
    inference_latency_ms: float
    embedding_generation_time_ms: float

@dataclass
class OrchestrationMetrics:
    """Agent orchestration metrics"""
    active_workflows: int
    completed_workflows: int
    failed_workflows: int
    average_workflow_duration: float
    coordination_overhead_ms: float
    message_throughput: float
    agent_coordination_score: float
    resource_allocation_efficiency: float

class MetricsAggregator:
    """Advanced metrics aggregation and analysis"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.data_windows: Dict[str, deque] = defaultdict(lambda: deque(maxlen=window_size))
        self.lock = threading.RLock()
    
    def add_metric(self, metric: MetricPoint):
        """Add a metric point to the aggregation window"""
        with self.lock:
            key = f"{metric.scope.value}.{metric.name}"
            self.data_windows[key].append(metric)
    
    def get_statistics(self, metric_key: str) -> Dict[str, float]:
        """Get statistical analysis of a metric"""
        with self.lock:
            window = self.data_windows.get(metric_key, deque())
            if not window:
                return {}
            
            values = [point.value for point in window if isinstance(point.value, (int, float))]
            if not values:
                return {}
            
            try:
                return {
                    'count': len(values),
                    'sum': sum(values),
                    'mean': mean(values),
                    'median': median(values),
                    'min': min(values),
                    'max': max(values),
                    'std_dev': stdev(values) if len(values) > 1 else 0.0,
                    'latest': values[-1],
                    'trend': self._calculate_trend(values)
                }
            except Exception as e:
                logging.error(f"Error calculating statistics for {metric_key}: {e}")
                return {}
    
    def _calculate_trend(self, values: List[float]) -> str:
        """Calculate trend direction"""
        if len(values) < 2:
            return "stable"
        
        recent = values[-min(10, len(values)):]
        older = values[-min(20, len(values)):-10] or values[:1]
        
        recent_avg = mean(recent)
        older_avg = mean(older)
        
        if recent_avg > older_avg * 1.05:
            return "increasing"
        elif recent_avg < older_avg * 0.95:
            return "decreasing"
        else:
            return "stable"

class MetricsCollector:
    """
    Enterprise-grade metrics collection system for YMERA multi-agent platform
    Provides comprehensive monitoring, analytics, and performance insights
    """
    
    def __init__(
        self,
        redis_client: redis.Redis,
        health_monitor=None,
        collection_interval: int = 30,
        retention_hours: int = 24,
        batch_size: int = 100,
        enable_detailed_profiling: bool = True
    ):
        self.redis_client = redis_client
        self.health_monitor = health_monitor
        self.collection_interval = collection_interval
        self.retention_hours = retention_hours
        self.batch_size = batch_size
        self.enable_detailed_profiling = enable_detailed_profiling
        
        # Core components
        self.logger = logging.getLogger(f"{__name__}.MetricsCollector")
        self.aggregator = MetricsAggregator()
        self.executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="metrics")
        
        # State management
        self.is_running = False
        self.is_initialized = False
        self.collection_task: Optional[asyncio.Task] = None
        self.cleanup_task: Optional[asyncio.Task] = None
        self.last_collection_time: Optional[datetime] = None
        
        # Performance tracking
        self.metrics_buffer: List[MetricPoint] = []
        self.buffer_lock = asyncio.Lock()
        self.collection_count = 0
        self.error_count = 0
        
        # System identification
        self.instance_id = str(uuid.uuid4())[:8]
        self.hostname = socket.gethostname()
        self.platform_info = {
            'system': platform.system(),
            'machine': platform.machine(),
            'processor': platform.processor(),
            'python_version': platform.python_version()
        }
        
        # Metric keys
        self.redis_keys = {
            'metrics': f"ymera:metrics:{self.instance_id}",
            'system_stats': f"ymera:system_stats:{self.instance_id}",
            'agent_stats': f"ymera:agent_stats:{self.instance_id}",
            'learning_stats': f"ymera:learning_stats:{self.instance_id}",
            'orchestration_stats': f"ymera:orchestration_stats:{self.instance_id}",
            'performance_summary': f"ymera:performance_summary:{self.instance_id}"
        }
        
        # Initialize baseline metrics
        self._baseline_metrics = {}
    
    async def initialize(self) -> bool:
        """Initialize the metrics collection system"""
        try:
            self.logger.info("Initializing YMERA Metrics Collection System...")
            
            # Test Redis connection
            await self.redis_client.ping()
            
            # Set up Redis data structures
            await self._setup_redis_structures()
            
            # Initialize baseline metrics
            await self._collect_baseline_metrics()
            
            # Start background tasks
            if not self.collection_task:
                self.collection_task = asyncio.create_task(self._collection_loop())
            
            if not self.cleanup_task:
                self.cleanup_task = asyncio.create_task(self._cleanup_loop())
            
            self.is_initialized = True
            self.logger.info("âœ… Metrics Collection System initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to initialize metrics collector: {e}")
            return False
    
    async def _setup_redis_structures(self):
        """Set up Redis data structures for metrics storage"""
        pipeline = self.redis_client.pipeline()
        
        # Set expiration for all metric keys
        for key in self.redis_keys.values():
            pipeline.expire(key, self.retention_hours * 3600)
        
        await pipeline.execute()
    
    async def _collect_baseline_metrics(self):
        """Collect baseline system metrics for comparison"""
        try:
            # System resources
            process = psutil.Process()
            system_info = {
                'boot_time': psutil.boot_time(),
                'cpu_count': psutil.cpu_count(),
                'memory_total': psutil.virtual_memory().total,
                'disk_total': psutil.disk_usage('/').total,
                'process_start_time': process.create_time()
            }
            
            self._baseline_metrics = system_info
            await self.redis_client.hset(
                f"{self.redis_keys['system_stats']}:baseline",
                mapping={k: json.dumps(v) for k, v in system_info.items()}
            )
            
        except Exception as e:
            self.logger.error(f"Error collecting baseline metrics: {e}")
    
    async def start_collection(self):
        """Start metrics collection"""
        if not self.is_initialized:
            await self.initialize()
        
        self.is_running = True
        self.logger.info("ðŸš€ Metrics collection started")
    
    async def stop_collection(self):
        """Stop metrics collection gracefully"""
        self.is_running = False
        
        # Cancel background tasks
        if self.collection_task and not self.collection_task.done():
            self.collection_task.cancel()
            try:
                await self.collection_task
            except asyncio.CancelledError:
                pass
        
        if self.cleanup_task and not self.cleanup_task.done():
            self.cleanup_task.cancel()
            try:
                await self.cleanup_task
            except asyncio.CancelledError:
                pass
        
        # Flush remaining metrics
        await self._flush_metrics_buffer()
        
        self.executor.shutdown(wait=True)
        self.logger.info("âœ… Metrics collection stopped")
    
    async def _collection_loop(self):
        """Main metrics collection loop"""
        while self.is_running:
            try:
                start_time = time.time()
                
                # Collect all metric types
                await asyncio.gather(
                    self._collect_system_metrics(),
                    self._collect_agent_metrics(),
                    self._collect_learning_metrics(),
                    self._collect_orchestration_metrics(),
                    self._collect_api_metrics(),
                    return_exceptions=True
                )
                
                # Flush metrics buffer
                await self._flush_metrics_buffer()
                
                collection_duration = time.time() - start_time
                self.collection_count += 1
                self.last_collection_time = datetime.utcnow()
                
                # Record collection performance
                await self._record_metric(
                    name="collection_duration_seconds",
                    value=collection_duration,
                    metric_type=MetricType.TIMER,
                    scope=MetricScope.SYSTEM,
                    tags={"component": "metrics_collector"}
                )
                
                # Sleep until next collection
                await asyncio.sleep(max(0, self.collection_interval - collection_duration))
                
            except Exception as e:
                self.error_count += 1
                self.logger.error(f"Error in metrics collection loop: {e}")
                await asyncio.sleep(self.collection_interval)
    
    async def _cleanup_loop(self):
        """Background cleanup of old metrics"""
        while self.is_running:
            try:
                await asyncio.sleep(3600)  # Run hourly
                await self._cleanup_old_metrics()
            except Exception as e:
                self.logger.error(f"Error in cleanup loop: {e}")
    
    async def _collect_system_metrics(self):
        """Collect comprehensive system resource metrics"""
        try:
            # Use thread executor for CPU-intensive operations
            system_metrics = await asyncio.get_event_loop().run_in_executor(
                self.executor, self._get_system_resource_metrics
            )
            
            # Convert to metric points
            timestamp = datetime.utcnow()
            metrics = [
                MetricPoint("cpu_usage_percent", system_metrics.cpu_percent, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("memory_usage_percent", system_metrics.memory_percent, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("memory_used_mb", system_metrics.memory_used_mb, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("disk_usage_percent", system_metrics.disk_usage_percent, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("network_bytes_sent", system_metrics.network_bytes_sent, timestamp, MetricType.COUNTER, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("network_bytes_recv", system_metrics.network_bytes_recv, timestamp, MetricType.COUNTER, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("active_connections", system_metrics.active_connections, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("thread_count", system_metrics.thread_count, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
                MetricPoint("process_count", system_metrics.process_count, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname}),
            ]
            
            # Add load average if available
            if system_metrics.load_average:
                for i, load in enumerate(system_metrics.load_average):
                    metrics.append(
                        MetricPoint(f"load_average_{i+1}min", load, timestamp, MetricType.GAUGE, MetricScope.SYSTEM, {"host": self.hostname})
                    )
            
            await self._add_metrics_to_buffer(metrics)
            
            # Store detailed system stats
            await self.redis_client.hset(
                self.redis_keys['system_stats'],
                f"snapshot_{int(timestamp.timestamp())}",
                json.dumps(asdict(system_metrics), default=str)
            )
            
        except Exception as e:
            self.logger.error(f"Error collecting system metrics: {e}")
    
    def _get_system_resource_metrics
(Content truncated due to size limit. Use page ranges or line ranges to read remaining content)